{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle  # For saving/loading Q-table\n",
    "\n",
    "\n",
    "# Initialize game state\n",
    "turns = 0\n",
    "board = np.zeros((4, 4), dtype=int)\n",
    "current_player = 1  # Player 1 starts\n",
    "\n",
    "def display_board(board):\n",
    "    print(\"\\nCurrent board:\")\n",
    "    for row in board:\n",
    "        display_row = []\n",
    "        for cell in row:\n",
    "            if cell == 0:\n",
    "                display_row.append(\".\")\n",
    "            elif cell == 1:\n",
    "                display_row.append(\"X\")\n",
    "            elif cell == 2:\n",
    "                display_row.append(\"O\")\n",
    "        print(\" \".join(display_row))\n",
    "    print()\n",
    "\n",
    "def check_legal_move(move) -> bool:\n",
    "    if 0 <= move < 4:\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter a number between 0 and 3.\")\n",
    "        return False\n",
    "\n",
    "def check_if_occupied(row, col, board) -> bool:\n",
    "    if board[row][col] != 0:\n",
    "        print(\"This spot is already occupied. Try again.\")\n",
    "        return True  # Spot is occupied\n",
    "    else:\n",
    "        return False  # Spot is free\n",
    "\n",
    "def check_win(board):\n",
    "    # Check horizontal\n",
    "    for i in range(4):\n",
    "        if board[i][0] == board[i][1] == board[i][2] != 0:\n",
    "            return True\n",
    "\n",
    "    # Check vertical\n",
    "    for j in range(4):\n",
    "        if board[0][j] == board[1][j] == board[2][j] != 0:\n",
    "            return True\n",
    "\n",
    "    # Check diagonals\n",
    "    if board[0][0] == board[1][1] == board[2][2] != 0:\n",
    "        return True\n",
    "    if board[0][2] == board[1][1] == board[2][0] != 0:\n",
    "        return True\n",
    "\n",
    "    return False  # No win yet\n",
    "\n",
    "def get_player_move(player):\n",
    "    while True:\n",
    "        try:\n",
    "            row = int(input(f\"Player {player} ({'X' if player ==1 else 'O'}), enter row (0, 1, or 2): \"))\n",
    "            if not check_legal_move(row):\n",
    "                continue\n",
    "            col = int(input(f\"Player {player} ({'X' if player ==1 else 'O'}), enter column (0, 1, or 2): \"))\n",
    "            if not check_legal_move(col):\n",
    "                continue\n",
    "            return row, col\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter integers between 0 and 2.\")\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, alpha=0.3, gamma=0.9, epsilon=0.2):\n",
    "        self.Q = {}  # Q-table as a dictionary\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "\n",
    "    def get_Q(self, state, action):\n",
    "        return self.Q.get((state, action), 0.0)\n",
    "\n",
    "    def choose_action(self, state, available_actions):\n",
    "        if random.uniform(0,1) < self.epsilon:\n",
    "            # Explore: choose a random action\n",
    "            action = random.choice(available_actions)\n",
    "        else:\n",
    "            # Exploit: choose the best action based on current Q-values\n",
    "            Q_values = [self.get_Q(state, a) for a in available_actions]\n",
    "            max_Q = max(Q_values)\n",
    "            # In case multiple actions have the same max Q-value\n",
    "            actions_with_max_Q = [a for a, q in zip(available_actions, Q_values) if q == max_Q]\n",
    "            action = random.choice(actions_with_max_Q)\n",
    "        return action\n",
    "\n",
    "    def learn(self, state, action, reward, next_state, next_available_actions, done):\n",
    "        old_Q = self.get_Q(state, action)\n",
    "        if done:\n",
    "            target = reward\n",
    "        else:\n",
    "            future_Q = [self.get_Q(next_state, a) for a in next_available_actions]\n",
    "            target = reward + self.gamma * max(future_Q, default=0)\n",
    "        self.Q[(state, action)] = old_Q + self.alpha * (target - old_Q)\n",
    "\n",
    "    def save_Q(self, filename=\"q_table.pkl\"):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.Q, f)\n",
    "\n",
    "    def load_Q(self, filename=\"q_table.pkl\"):\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.Q = pickle.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(\"Q-table file not found. Starting with an empty Q-table.\")\n",
    "\n",
    "def train_agent(agent, episodes=50000):\n",
    "    for episode in range(episodes):\n",
    "        # Initialize the game\n",
    "        board = np.zeros((4, 4), dtype=int)\n",
    "        turns = 0\n",
    "        done = False\n",
    "        current_player = 1  # Agent starts first\n",
    "\n",
    "        while not done:\n",
    "            state = tuple(board.flatten())\n",
    "            available_actions = [i for i in range(16) if board.flatten()[i] == 0]\n",
    "\n",
    "            if current_player == 1:\n",
    "                # Agent's turn\n",
    "                action = agent.choose_action(state, available_actions)\n",
    "                row, col = divmod(action, 4)\n",
    "                board[row][col] = current_player\n",
    "                turns += 1\n",
    "\n",
    "                if check_win(board):\n",
    "                    reward = 1  # Agent wins\n",
    "                    agent.learn(state, action, reward, None, [], True)\n",
    "                    done = True\n",
    "                elif turns == 16:\n",
    "                    reward = 0  # Draw\n",
    "                    agent.learn(state, action, reward, None, [], True)\n",
    "                    done = True\n",
    "                else:\n",
    "                    # Opponent's turn next\n",
    "                    next_available_actions = [i for i in range(16) if board.flatten()[i] == 0]\n",
    "                    agent.learn(state, action, 0, tuple(board.flatten()), next_available_actions, False)\n",
    "                    current_player = 2\n",
    "            else:\n",
    "                # Opponent's turn (Random)\n",
    "                opp_action = random.choice(available_actions)\n",
    "                board[opp_action // 4][opp_action % 4] = current_player\n",
    "                turns += 1\n",
    "\n",
    "                if check_win(board):\n",
    "                    reward = -1  # Agent loses\n",
    "                    agent.learn(state, action, reward, None, [], True)\n",
    "                    done = True\n",
    "                elif turns == 16:\n",
    "                    reward = 0  # Draw\n",
    "                    agent.learn(state, action, reward, None, [], True)\n",
    "                    done = True\n",
    "                else:\n",
    "                    current_player = 1  # Agent's turn\n",
    "\n",
    "        # Optional: Print progress\n",
    "        if (episode+1) % 10000 == 0:\n",
    "            print(f\"Episode {episode+1}/{episodes} completed.\")\n",
    "\n",
    "    # Save the trained Q-table\n",
    "    agent.save_Q()\n",
    "    print(\"Training completed and Q-table saved.\")\n",
    "\n",
    "def play_against_agent(agent):\n",
    "    board = np.zeros((4, 4), dtype=int)\n",
    "    turns = 0\n",
    "    current_player = 1  # Agent starts first\n",
    "\n",
    "    while True:\n",
    "        display_board(board)\n",
    "        state = tuple(board.flatten())\n",
    "        available_actions = [i for i in range(16) if board.flatten()[i] == 0]\n",
    "\n",
    "        if current_player == 1:\n",
    "            # Agent's turn\n",
    "            action = agent.choose_action(state, available_actions)\n",
    "            row, col = divmod(action, 4)\n",
    "            board[row][col] = current_player\n",
    "            turns += 1\n",
    "\n",
    "            if check_win(board):\n",
    "                display_board(board)\n",
    "                print(f\"Agent (X) wins!\")\n",
    "                break\n",
    "            elif turns == 16:\n",
    "                display_board(board)\n",
    "                print(\"It's a draw!\")\n",
    "                break\n",
    "            else:\n",
    "                current_player = 2\n",
    "        else:\n",
    "            # Human player's turn\n",
    "            row, col = get_player_move(current_player)\n",
    "            action = row * 4 + col\n",
    "            if board[row][col] != 0:\n",
    "                print(\"Spot occupied! Choose another move.\")\n",
    "                continue\n",
    "            board[row][col] = current_player\n",
    "            turns += 1\n",
    "\n",
    "            if check_win(board):\n",
    "                display_board(board)\n",
    "                print(f\"Player {current_player} ({'O'}) wins!\")\n",
    "                break\n",
    "            elif turns == 9:\n",
    "                display_board(board)\n",
    "                print(\"It's a draw!\")\n",
    "                break\n",
    "            else:\n",
    "                current_player = 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent = QLearningAgent()\n",
    "    # Attempt to load existing Q-table\n",
    "    agent.load_Q()\n",
    "\n",
    "    while True:\n",
    "        print(\"\\n--- Tic-Tac-Toe with Q-Learning Agent ---\")\n",
    "        print(\"1. Train Agent\")\n",
    "        print(\"2. Play Against Agent\")\n",
    "        print(\"3. Exit\")\n",
    "        choice = input(\"Enter your choice: \")\n",
    "\n",
    "        if choice == '1':\n",
    "            try:\n",
    "                episodes = int(input(\"Enter number of training episodes (e.g., 50000): \"))\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Using default 50000 episodes.\")\n",
    "                episodes = 50000\n",
    "            train_agent(agent, episodes=episodes)\n",
    "        elif choice == '2':\n",
    "            # Set epsilon to 0 for exploitation (use learned policy)\n",
    "            original_epsilon = agent.epsilon\n",
    "            agent.epsilon = 0\n",
    "            play_against_agent(agent)\n",
    "            agent.epsilon = original_epsilon\n",
    "        elif choice == '3':\n",
    "            print(\"Exiting the game.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please select 1, 2, or 3.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
